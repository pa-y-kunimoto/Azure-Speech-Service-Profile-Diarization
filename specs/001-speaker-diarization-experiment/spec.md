# Feature Specification: 話者分離・話者認識実験アプリケーション

**Feature Branch**: `001-speaker-diarization-experiment`  
**Created**: 2025-12-01  
**Status**: Draft  
**Input**: User description: "Azure Speech Service のダイアライゼーション機能を使った話者認識実験"

## User Scenarios & Testing *(mandatory)*

<!--
  IMPORTANT: User stories should be PRIORITIZED as user journeys ordered by importance.
  Each user story/journey must be INDEPENDENTLY TESTABLE - meaning if you implement just ONE of them,
  you should still have a viable MVP (Minimum Viable Product) that delivers value.
-->

### User Story 1 - 音声プロフィールの作成（アップロード） (Priority: P1)

ユーザーは既存の音声ファイルをアップロードして、話者の「音声プロフィール」を作成できる。音声プロフィールには名前を付けて識別できるようにする。

**Why this priority**: 話者認識の基盤となる機能。音声プロフィールがなければ話者を識別できないため、最優先。

**Independent Test**: 音声ファイルをアップロードし、プロフィール一覧に表示されることを確認できる。

**Acceptance Scenarios**:

1. **Given** ユーザーがアプリケーションを開いている, **When** 音声ファイル（WAV/MP3）をアップロードし名前を入力する, **Then** 音声プロフィールがセッションストレージに保存され、プロフィール一覧に表示される
2. **Given** プロフィール一覧が表示されている, **When** 既存のプロフィールを削除する, **Then** そのプロフィールが一覧から削除される
3. **Given** ユーザーが音声ファイルを選択している, **When** 名前を入力せずに保存しようとする, **Then** 名前が必須であることを示すエラーメッセージが表示される

---

### User Story 2 - 音声プロフィールの作成（ブラウザ録音） (Priority: P2)

ユーザーはブラウザのマイクを使って直接音声を録音し、音声プロフィールを作成できる。

**Why this priority**: アップロード機能の代替手段として、より手軽にプロフィールを作成できる。P1の次に実装。

**Independent Test**: ブラウザで録音ボタンを押し、音声を録音してプロフィールとして保存できることを確認。

**Acceptance Scenarios**:

1. **Given** ユーザーがプロフィール作成画面にいる, **When** 録音ボタンを押してマイクで話し、停止ボタンを押す, **Then** 録音された音声がプレビュー再生できる
2. **Given** 録音が完了している, **When** 名前を入力して保存する, **Then** 録音された音声が音声プロフィールとしてセッションストレージに保存される
3. **Given** ユーザーが録音を開始しようとする, **When** ブラウザがマイクへのアクセスを拒否する, **Then** マイクアクセスが必要である旨のエラーメッセージが表示される

---

### User Story 3 - 話者分離セッションの開始と音声プロフィール登録 (Priority: P3)

ユーザーは保存済みの音声プロフィールを選択し、Azure Speech Service の話者分離セッションを開始できる。選択されたプロフィールの音声データをセッションに送信し、各話者の speakerId を取得・保持する。

**Why this priority**: 話者認識の核心部分。プロフィールから speakerId を取得することで、後続のリアルタイム認識が可能になる。

**Independent Test**: プロフィールを選択してセッション開始ボタンを押し、各プロフィールに対応する speakerId が画面に表示されることを確認。

**Acceptance Scenarios**:

1. **Given** 複数の音声プロフィールが保存されている, **When** 使用するプロフィールを選択してセッション開始を押す, **Then** Azure Speech Service に接続し、各プロフィールの音声が順番に送信される
2. **Given** 音声プロフィールが Azure に送信されている, **When** Azure から speakerId を含むレスポンスが返ってくる, **Then** プロフィール名と speakerId のマッピングが画面に表示される
3. **Given** プロフィールが1つも選択されていない, **When** セッション開始を押す, **Then** 少なくとも1つのプロフィールを選択するよう促すメッセージが表示される

---

### User Story 4 - リアルタイム話者認識 (Priority: P4)

セッション開始後、ユーザーはブラウザのマイクから音声を入力し、リアルタイムで話者を認識できる。認識結果は speakerId と共に画面に表示され、既知のプロフィールと一致する場合はプロフィール名で表示される。

**Why this priority**: 実験の最終目標。P3でセッションが確立された後に実行可能。

**Independent Test**: セッション開始後にマイクで話すと、話者名（または speakerId）と発話内容がリアルタイムで画面に表示されることを確認。

**Acceptance Scenarios**:

1. **Given** 話者分離セッションがアクティブで、音声プロフィールが登録済み, **When** ユーザーがマイクに向かって話す, **Then** 発話内容がリアルタイムでテキスト表示され、話者名（または speakerId）が付与される
2. **Given** 複数の話者が会話している, **When** 話者が切り替わる, **Then** それぞれの発話が正しい話者に紐づいて表示される
3. **Given** 登録されていない話者が発話する, **When** Azure が新しい speakerId を返す, **Then** 「Unknown Speaker (speakerId)」のように表示される
4. **Given** リアルタイム認識中, **When** セッション停止ボタンを押す, **Then** マイク入力が停止し、Azure との接続が終了する

---

### User Story 5 - セッション結果の確認 (Priority: P5)

セッション終了後、ユーザーは会話の全体像（誰がいつ何を話したか）をタイムライン形式で確認できる。

**Why this priority**: 実験結果の振り返りに必要。MVPには含まれないが、実験の効果検証に有用。

**Independent Test**: セッション終了後に発話履歴が時系列で表示されることを確認。

**Acceptance Scenarios**:

1. **Given** セッションが終了している, **When** 結果画面を表示する, **Then** 全発話が時系列順にタイムライン表示される
2. **Given** 結果が表示されている, **When** 特定の話者でフィルタリングする, **Then** その話者の発話のみが表示される

---

### Edge Cases

- 音声ファイルが破損している、またはサポートされていない形式の場合はどうなるか？ → エラーメッセージを表示し、サポート形式を案内する
- 長時間のセッションでブラウザのセッションストレージ容量を超えた場合はどうなるか？ → 警告を表示し、古いプロフィールの削除を促す
- Azure Speech Service への接続が失敗した場合はどうなるか？ → リトライ機能を提供し、接続状態を明示する
- ネットワークが途中で切断された場合はどうなるか？ → 自動再接続を試み、失敗時はユーザーに通知する
- 音声プロフィールの音声が短すぎて話者特定に不十分な場合はどうなるか？ → 最低録音時間（推定5秒以上）を設け、満たさない場合は警告を表示する

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: システムは WAV および MP3 形式の音声ファイルのアップロードをサポートすること
- **FR-002**: システムはブラウザのマイクを使用した音声録音機能を提供すること
- **FR-003**: 音声プロフィールはプロフィール名と音声データをセッションストレージに保存すること
- **FR-004**: ユーザーは複数の音声プロフィールを作成・管理（追加・削除）できること
- **FR-005**: システムは Azure Speech Service の話者分離（Diarization）API と連携すること
- **FR-006**: セッション開始時、選択された音声プロフィールを順番に Azure に送信し、speakerId を取得すること
- **FR-007**: システムはプロフィール名と speakerId のマッピングをセッション中保持すること
- **FR-008**: システムはブラウザのマイク入力をリアルタイムで Azure Speech Service に送信すること
- **FR-009**: Azure から返される認識結果（テキスト、speakerId）をリアルタイムで画面に表示すること
- **FR-010**: 既知の speakerId はプロフィール名で、未知の speakerId は「Unknown Speaker」として表示すること
- **FR-011**: ユーザーはセッションの開始・停止を制御できること
- **FR-012**: セッション終了後、発話履歴をタイムライン形式で表示できること

### Key Entities

- **VoiceProfile（音声プロフィール）**: 話者を識別するための音声サンプル。名前、音声データ（Blob）、作成日時を持つ
- **DiarizationSession（話者分離セッション）**: Azure Speech Service との接続セッション。セッションID、接続状態、開始時刻を持つ
- **SpeakerMapping（話者マッピング）**: 音声プロフィールと Azure が割り当てた speakerId の対応関係
- **Utterance（発話）**: 認識された発話。テキスト、話者ID、タイムスタンプを持つ

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: ユーザーは30秒以内に音声プロフィールを作成できる（アップロードまたは録音から保存まで）
- **SC-002**: セッション開始から音声プロフィールの話者登録完了まで、プロフィール1件あたり10秒以内で処理される
- **SC-003**: リアルタイム認識時、発話終了から画面表示まで3秒以内の遅延で結果が表示される
- **SC-004**: 登録済みの話者の認識精度が80%以上である（同じ話者の発話が正しくマッピングされる）
- **SC-005**: 3人以上の話者を同時に区別できる
- **SC-006**: セッションが10分以上継続しても安定して動作する
